# ğŸ›« ATC Voice Communications Dashboard (Voice-to-Text)

## ğŸ“Œ Project Overview
This project is part of the **GMU DAEN Capstone (Fall 2025)** and focuses on building an **Air Traffic Control (ATC) Voice Communications Dashboard**.  
The system ingests live or recorded ATC audio, converts it into text using Speech-to-Text (STT) models, applies Natural Language Processing (NLP) for analysis, and visualizes insights in an interactive dashboard.

---

## ğŸ¯ Objectives
- Ingest and process **ATC audio recordings** (e.g., LiveATC streams).  
- Apply **Speech-to-Text (STT)** models such as Whisper, Vosk, or Azure Speech SDK.  
- Perform **NLP analysis** (keyword spotting, call sign detection, anomaly detection).  
- Develop a **real-time dashboard** to visualize:
  - Transcripts
  - Communication timelines
  - Flight activity summaries
  - Alerts/anomalies  

---

## ğŸ—ï¸ Repository Structure
atc-voice-dashboard/
â”‚â”€â”€ README.md

â”‚â”€â”€ .gitignore

â”‚â”€â”€ requirements.txt # Python dependencies

â”‚â”€â”€ src/ # Core source code

â”‚ â”œâ”€â”€ data_ingestion/ # Scripts to fetch/stream ATC audio (LiveATC, etc.)

â”‚ â”œâ”€â”€ preprocessing/ # Audio cleaning, segmentation

â”‚ â”œâ”€â”€ speech_to_text/ # STT pipeline (Whisper, Vosk, or Azure Speech SDK)

â”‚ â”œâ”€â”€ nlp_analysis/ # Keyword spotting, topic modeling, anomaly detection

â”‚ â”œâ”€â”€ dashboard/ # Streamlit/Dash app for visualization

â”‚ â””â”€â”€ utils/ # Helper functions (logging, config)

â”‚â”€â”€ notebooks/ # Jupyter/EDA experiments

â”‚â”€â”€ data/ # Sample data (small clips, transcripts)

â”‚â”€â”€ tests/ # Unit tests

â”‚â”€â”€ docs/ # Project docs & capstone deliverables


---

## âš™ï¸ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/<your-username>/atc-voice-dashboard.git
   cd atc-voice-dashboard
   
## Create a virtual environment & activate it:
--
python3 -m venv venv
source venv/bin/activate   # On macOS/Linux
venv\Scripts\activate      # On Windows

--

## Install dependencies:


pip install -r requirements.txt
--

ğŸ§° Tech Stack
Programming: Python

Audio Processing: pydub, librosa (TBD)

Speech-to-Text: OpenAI Whisper / Vosk / Azure Speech SDK (TBD)

NLP: Hugging Face Transformers, spaCy (TBD)

Dashboard: Streamlit / Dash / Plotly (TBD)

Data Handling: Pandas, NumPy

Optional Deployment: Docker (TBD)

---

ğŸ“Š Deliverables
âœ… Final Project Report

âœ… Capstone Showcase Presentation

âœ… GitHub Repository (this repo)

âœ… Working Dashboard Prototype

--

ğŸ“œ License
This project is released under the Apache 2.0 License unless otherwise specified by the partner.

